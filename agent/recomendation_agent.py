import uuid
from autogen import ConversableAgent
import psycopg2
from pydantic import BaseModel
from env import env
from models.chat import ChatbotRequest
from typing import Dict, Any, List
import re
import json
import time
from sqlalchemy import create_engine, text
from fastapi import APIRouter
from tool_call.qdrant_search import QSearch
from services.product import ProductService
from embedding.search import product_semantic_search

class AgentResponse(BaseModel):
    response: str


router = APIRouter( prefix="/chatbot", tags=["recomendation"])

llm_openai = {
    "model": env.OPENAI_API_MODEL,
    "api_key": env.OPENAI_API_KEY
}

class QdrantAgent:
    def __init__(self):
        self.llm_config = llm_openai
        self.db_schema = self._get_db_schema()
        self.agent = self._create_qdrant_agent()
    def _get_db_schema(self) -> str:
        return """
        point struct payload (Relational Database):

        Table: products
        Columns:
        - id: INTEGER PRIMARY KEY
        - title: TEXT NOT NULL
        """
    def _create_qdrant_agent(self) -> ConversableAgent:
        system_message = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia Qdrant (vector database) vá»›i nhiá»‡m vá»¥:
        1. PhÃ¢n tÃ­ch cÃ¢u há»i ngÆ°á»i dÃ¹ng vá» sáº£n pháº©m, Ä‘Ã¡nh giÃ¡ vÃ  lá»c cÃ¡c thÃ´ng tin quan trá»ng Ä‘á»ƒ táº¡o truy váº¥n Qdrant hiá»‡u quáº£.
        2. XÃ¡c Ä‘á»‹nh collection Qdrant cáº§n truy váº¥n vÃ  tá»« khÃ³a cáº§n nháº­p vÃ o Ä‘á»ƒ tÃ¬m kiáº¿m
        3. Táº¡o duy nháº¥t má»™t JSON mÃ´ táº£ truy váº¥n Qdrant dá»±a trÃªn phÃ¢n tÃ­ch cá»§a báº¡n, chuá»—i truy váº¥n lÃ  mÃ´ táº£ sáº£n pháº©m.
        4. Chá»‰ tráº£ vá» JSON, khÃ´ng thÃªm báº¥t ká»³ giáº£i thÃ­ch nÃ o khÃ¡c.


        {self.db_schema}

        HÃ£y tráº£ vá» mÃ´ táº£ truy váº¥n Qdrant dÆ°á»›i dáº¡ng JSON:

        ```json
        {{
            "query_text": "giÃ¡ trá»‹ Ä‘áº§u vÃ o dáº¡ng chuá»—i Ä‘á»ƒ lÃ  description tÃ¬m kiáº¿m embedding",
        }}
        ```
        """
        return ConversableAgent(
            name="vector_expert",
            system_message=system_message,
            llm_config=self.llm_config,
            human_input_mode="NEVER"
        )
    def _extract_qdrant_query(self, response: str):
        print(f"Raw response for Qdrant query extraction: {response}")
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL) or \
                     re.search(r'(\{.*?\})', response, re.DOTALL)
        if not json_match:
            print("ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©111ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©")
            return {"collection_name": "products", "payload": "", "limit": 5}
        try:
            print("ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©232321ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©")
            return json.loads(json_match.group(1))
        except json.JSONDecodeError as e:
            print("ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©3232132131312ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©ğŸ¥©")
            return {"collection_name": "products", "payload": "", "limit": 5}

    def _execute_qdrant_query(self, query_info: Dict[str, Any], user_id: str, top_k = 5):
        id = str(user_id)
        print(id)
        print("ğŸ¥¨ğŸ¥ğŸ¥¯ğŸ§€ğŸ¥–ğŸ ğŸ¥ŸğŸ¥ ğŸ¤ğŸ¤ğŸ£ğŸ£")
        print(f"Executing Qdrant query with info: {query_info}, id: {id}, top_k: {top_k}")
        result =  product_semantic_search(query_info, id, top_k)
        print(result)
        return result

    def _generate_explanation(self,  query_result: List[Dict], user_query: str):
        if not query_result:
            return {"response": "KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n."}

        print("ğŸ”ğŸŸğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ´ğŸŒ­ğŸ•ğŸ¥ª")
        data_description = f"ÄÃ¢y lÃ  má»™t sá»‘ sáº£n pháº©m mÃ  tÃ´i tÃ¬m tháº¥y cho báº¡n: "
        top_products = ", ".join(
            f"{item['title']} ({item.get('price', 'N/A')} VND) {item.get('brand', 'N/A')}" for item in query_result[:3]
        )
        data_description += f" {top_products}."
        print(data_description)
        print("ğŸ”ğŸŸğŸŒ­ğŸ•ğŸ¥ªğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ¥™ğŸ§†ğŸ—ğŸ–ğŸ¥©ğŸ ")
        explanation_prompt = f"""
        Báº¡n lÃ  1 trá»£ lÃ½ AI thÃ´ng minh, lÃ m viá»‡c cho Navitech.
        Báº¡n sáº½ nháº­n Ä‘áº§u vÃ o lÃ  má»™t cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vá» sáº£n pháº©m vÃ  má»™t mÃ´ táº£ dá»¯ liá»‡u tráº£ vá» tá»« Qdrant.
        CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {user_query}
        MÃ´ táº£ dá»¯ liá»‡u tráº£ vá»: {data_description}
        HÃ£y viáº¿t cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ giá»›i thiá»‡u vá» sáº£n pháº©m.
        """
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=explanation_prompt,
        )
        return response.text



    async def process_query(self, user_query: str, user_id: str):
        try:
            prompt = f"""HÃ£y phÃ¢n tÃ­ch vÃ  táº¡o truy váº¥n Qdrant cho cÃ¢u há»i sau: "{user_query}" """
            print(f"Prompt: {prompt}")
            agent_response = await self.agent.a_generate_reply(messages=[{"role": "user", "content": prompt}])
            print(f"Agent Response: {agent_response}")
            print(f"Agent Response: {agent_response.get('content')}")
            query_info = self._extract_qdrant_query(agent_response.get('content'))
            print("ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—ğŸ¥—")
            print(f"Extracted Qdrant Query Info: {query_info}")
            print(query_info.get("query_text"))
            raw_results = self._execute_qdrant_query(query_info.get("query_text"), user_id=str(user_id), top_k=5)
            print("ğŸ¥„ğŸ¥„ğŸ´ğŸ¥„ğŸ´ğŸ´ğŸ´ğŸ´ğŸ½ğŸ½ğŸ½ğŸ½ğŸ¥„ğŸ¥„ğŸ¥„ğŸ´ğŸ´ğŸ´ğŸ´ğŸ€ğŸŒ¿ğŸŒ¿ğŸğŸğŸ€ğŸğŸŒ¾ğŸ¥œğŸŒ±ğŸŒ´ğŸŒ³ğŸŒ³ğŸŒ¼ğŸŒ·ğŸŒ±â˜˜â˜˜")
            print(f"Raw Results: {raw_results}")
            # TrÃ­ch product_id vÃ  gá»i ProductServices.get
            products = []
            for pid in raw_results:
                if pid:
                    product = ProductService.get_some_infor(pid)
                    if product:
                        products.append(product)

            print("ğŸ‡ğŸ‰ğŸŠğŸ‹ğŸŒğŸğŸ¥­ğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ¥ğŸ¥¥ğŸ¥‘ğŸ†ğŸ¥”ğŸ¥•ğŸŒ½ğŸŒ¶ï¸ğŸ«‘ğŸ¥’ğŸ¥¬")
            print(f"Products: {products}")
            explanation = self._generate_explanation(products, user_query)
            print(f"Explanation: {explanation}")
            return explanation

        except Exception as e:
            return f"ÄÃ£ xáº£y ra lá»—i khi thá»±c hiá»‡n truy váº¥n: {e}"

@router.post("/recomendation", response_model=str)
async def chatbot_endpoint(request: ChatbotRequest, user_id: str):
    try:
        message = request.message

        # # LÆ°u tin nháº¯n vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u
        # message_repository = MessageRepository()
        # message_payload = CreateMessagePayload(
        #     chat_id=request.chat_id,
        #     role="user",
        #     content=message
        # )
        # message_repository.create(message_payload)
        # Táº¡o cÃ¢u há»i cho agent
        question = message
        agent = QdrantAgent()
        response = await agent.process_query(user_query=question , user_id=user_id)
        # LÆ°u pháº£n há»“i vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u
        # response_payload = CreateMessagePayload(
        #     chat_id=request.chat_id,
        #     role="assistant",
        #     content=response
        # )
        # message_repository.create(response_payload)
        return response
    except Exception as e:
        return "ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ yÃªu cáº§u."