"""
DocumentRetrievalAgent - TÃ¬m kiáº¿m thÃ´ng tin tá»« knowledge base

Agent nÃ y xá»­ lÃ½:
- Truy váº¥n thÃ´ng tin tá»« documents Ä‘Ã£ upload
- Semantic search trÃªn Qdrant collection "documents"
- RAG (Retrieval-Augmented Generation) Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn knowledge base
"""

from autogen import ConversableAgent
from env import env
from models.chat import ChatbotRequest
from fastapi import APIRouter
from typing import List, Dict, Any
from qdrant_client import QdrantClient, models
from embedding.generate_embeddings import generate_embedding
from embedding.search import document_semantic_search   
import json
import re

router = APIRouter(prefix="/chatbot", tags=["Document Retrieval Agent"])

llm_config = {
    "model": "gemini-2.5-flash",
    "api_key": env.GEMINI_API_KEY,
    "api_type": "google"
}

class DocumentRetrievalAgent:
    def __init__(self):
        self.llm_config = llm_config
        self.qdrant = QdrantClient("http://localhost:6334")
        self.collection_name = "documents"
        
    def _search_documents(self, query: str, user_id: str, top_k: int = 5) -> List[Dict]:
        """
        TÃ¬m kiáº¿m documents trong Qdrant collection
        
        Args:
            query: Query string
            user_id: User ID Ä‘á»ƒ filter
            top_k: Sá»‘ lÆ°á»£ng chunks tráº£ vá»
            
        Returns:
            List of relevant document chunks vá»›i payload
        """
        try:
            # Generate embedding cho query
            print("ðŸ›ðŸ›ðŸšðŸœðŸœðŸ¦ªðŸ¦ªðŸ ðŸ ðŸ£ðŸ£ðŸ£ðŸ±ðŸ¥¡ðŸ¥¡")
            print(f"querry: {query}, user_id: {user_id}, top_k: {top_k}")
            
            # Search trong Qdrant vá»›i filter by user_id
            chunks = document_semantic_search(query, user_id, top_k, COLLECTION_NAME=self.collection_name)

            print(f"ðŸ“š Found {len(chunks)} relevant document chunks")
            print(chunks)

            # results = self.qdrant.query_points(
            #     collection_name=self.collection_name,
            #     query=query_embedding,
            #     using="default",
            #     query_filter=models.Filter(
            #         must=[
            #             models.FieldCondition(
            #                 key="user_id",
            #                 match=models.MatchValue(value=user_id)
            #             )
            #         ]
            #     ),
            #     limit=top_k,
            #     with_payload=True,
            #     with_vectors=False
            # )
            
            # Extract chunks vá»›i payload
            # chunks = []
            # for point in results.points:
            #     chunks.append({
            #         "id": point.id,
            #         "score": point.score,
            #         "text": point.payload.get("text", ""),
            #         "document_name": point.payload.get("document_name", "Unknown"),
            #         "chunk_index": point.payload.get("chunk_index", 0),
            #         "total_chunks": point.payload.get("total_chunks", 0),
            #         "created_at": point.payload.get("created_at", "")
            #     })
            
            print(f"ðŸ“š Found {len(chunks)} relevant document chunks")
            for chunk in chunks[:3]:  # Log top 3
                print(f"   - {chunk['document_name']} (chunk {chunk['chunk_index']}/{chunk['total_chunks']}) - Score: {chunk['score']:.3f}")
            
            return chunks
            
        except Exception as e:
            print(f"âŒ Error searching documents: {str(e)}")
            return []
    
    def _create_rag_agent(self) -> ConversableAgent:
        """
        Táº¡o RAG agent Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn retrieved documents
        """
        system_message = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh cá»§a NAVITECH, chuyÃªn tráº£ lá»i cÃ¢u há»i dá»±a trÃªn knowledge base.

NHIá»†M Vá»¤:
1. PhÃ¢n tÃ­ch cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
2. Sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c documents Ä‘Ã£ Ä‘Æ°á»£c retrieve
3. Tráº£ lá»i chÃ­nh xÃ¡c, Ä‘áº§y Ä‘á»§ dá»±a trÃªn context
4. TrÃ­ch dáº«n nguá»“n (tÃªn document) náº¿u cÃ³ thá»ƒ

NGUYÃŠN Táº®C:
- Chá»‰ tráº£ lá»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin trong context â†’ NÃ³i rÃµ "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin"
- TrÃ­ch dáº«n document name khi tráº£ lá»i
- Náº¿u context khÃ´ng Ä‘á»§ â†’ Há»i thÃªm chi tiáº¿t

OUTPUT FORMAT:
Tráº£ lá»i trá»±c tiáº¿p báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n, cÃ³ cáº¥u trÃºc rÃµ rÃ ng.
"""
        return ConversableAgent(
            name="document_rag_expert",
            system_message=system_message,
            llm_config=self.llm_config,
            human_input_mode="NEVER"
        )
    
    async def process_query(self, query: str, user_id: str, top_k: int = 5) -> str:
        """
        Xá»­ lÃ½ query vá»›i RAG pipeline
        
        Args:
            query: CÃ¢u há»i cá»§a user
            user_id: User ID
            top_k: Sá»‘ lÆ°á»£ng chunks retrieve
            
        Returns:
            Response string vá»›i thÃ´ng tin tá»« knowledge base
        """
        try:
            print(f"ðŸ“– DocumentRetrievalAgent processing: {query}")
            
            # [1] Retrieve relevant documents
            chunks = self._search_documents(query, user_id, top_k)
            
            if not chunks or len(chunks) == 0:
                return """Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong knowledge base.

CÃ³ thá»ƒ vÃ¬:
- ChÆ°a cÃ³ document nÃ o Ä‘Æ°á»£c upload vá» chá»§ Ä‘á» nÃ y
- CÃ¢u há»i chÆ°a Ä‘á»§ cá»¥ thá»ƒ

Báº¡n cÃ³ thá»ƒ:
- Upload thÃªm documents vá» chá»§ Ä‘á» nÃ y
- Diá»…n Ä‘áº¡t cÃ¢u há»i chi tiáº¿t hÆ¡n
- Há»i vá» sáº£n pháº©m hoáº·c chá»§ Ä‘á» khÃ¡c

TÃ´i luÃ´n sáºµn sÃ ng há»— trá»£! ðŸ˜Š"""
            
            # [2] Build context tá»« retrieved chunks
            context = self._build_context(chunks)
            
            # [3] Generate answer vá»›i RAG agent
            agent = self._create_rag_agent()
            
            prompt = f"""
CÃ¢u há»i: {query}

Context tá»« knowledge base:
{context}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context trÃªn.
"""
            
            response = await agent.a_generate_reply(
                messages=[{"role": "user", "content": prompt}]
            )
            
            answer = response.get('content', '')
            
            # [4] Add metadata (sources)
            sources = self._extract_sources(chunks)
            if sources:
                answer += f"\n\nðŸ“š **Nguá»“n tham kháº£o:**\n"
                for source in sources:
                    answer += f"- {source}\n"
            
            return answer
            
        except Exception as e:
            print(f"âŒ Error in DocumentRetrievalAgent: {str(e)}")
            import traceback
            traceback.print_exc()
            return "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi tÃ¬m kiáº¿m thÃ´ng tin. Vui lÃ²ng thá»­ láº¡i sau."
    
    def _build_context(self, chunks: List[Dict]) -> str:
        """
        Build context string tá»« retrieved chunks
        """
        context_parts = []
        
        # Group by document
        docs = {}
        for chunk in chunks:
            doc_name = chunk['document_name']
            if doc_name not in docs:
                docs[doc_name] = []
            docs[doc_name].append(chunk)
        
        # Format context
        for doc_name, doc_chunks in docs.items():
            context_parts.append(f"\n--- Document: {doc_name} ---")
            
            # Sort by chunk_index
            doc_chunks.sort(key=lambda x: x['chunk_index'])
            
            for chunk in doc_chunks:
                text = chunk['text'].strip()
                if text:
                    context_parts.append(f"[Chunk {chunk['chunk_index']}/{chunk['total_chunks']}]: {text}")
        
        return "\n".join(context_parts)
    
    def _extract_sources(self, chunks: List[Dict]) -> List[str]:
        """
        Extract unique document names as sources
        """
        sources = set()
        for chunk in chunks:
            doc_name = chunk.get('document_name', 'Unknown')
            if doc_name != 'Unknown':
                sources.add(doc_name)
        return sorted(list(sources))


@router.post("/document_retrieval", response_model=str)
async def document_retrieval_endpoint(
    request: ChatbotRequest,
    user_id: str,
    top_k: int = 5
):
    """
    Endpoint Ä‘á»ƒ truy váº¥n knowledge base
    """
    agent = DocumentRetrievalAgent()
    response = await agent.process_query(
        query=request.message,
        user_id=user_id,
        top_k=top_k
    )
    return response
