#!/usr/bin/env python3
"""
Database Manager - Quáº£n lÃ½ PostgreSQL database cho crawler
Má»—i website cÃ³ báº£ng riÃªng
"""
import sys
import psycopg2
from psycopg2.extras import execute_values
import json
import os
from datetime import datetime
import zlib
import uuid as uuid_lib

# Add parent directory to path to import env
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from env import env

class DatabaseManager:
    # âš™ï¸ Configuration - Set cá»©ng máº·c Ä‘á»‹nh
    DB_HOST = 'localhost'
    DB_PORT = env.POSTGRES_PORT
    DB_USER = 'postgres'
    DB_PASSWORD = 'mypassword'
    DB_NAME = 'chatbot'
    CONNECT_TIMEOUT = 10
    BATCH_PAGE_SIZE = 100
    
    # Website ID mapping - simple 1, 2, 3...
    WEBSITE_MAPPING = {
        'mypc.vn': 1,
        'phongvu.vn': 2,
        'tiki.vn': 3,
        'nguyencongpc.vn': 4,
    }
    NEXT_WEBSITE_ID = 5  # For new websites
    
    def __init__(self, host=None, port=None, user=None, password=None, dbname=None):
        self.host = host or self.DB_HOST
        self.port = port or self.DB_PORT
        self.user = user or self.DB_USER
        self.password = password or self.DB_PASSWORD
        self.dbname = dbname or self.DB_NAME
        self.conn = None
    
    def connect(self):
        """Káº¿t ná»‘i tá»›i database"""
        try:
            self.conn = psycopg2.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                dbname=self.dbname,
                connect_timeout=self.CONNECT_TIMEOUT
            )
            print(f"âœ… PostgreSQL connected: {self.user}@{self.host}:{self.port}/{self.dbname}")
            return self.conn
        except psycopg2.Error as e:
            print(f"âŒ Connection failed: {e}")
            return None
    
    def reset_schema(self):
        """DROP vÃ  recreate báº£ng products tá»« init.sql"""
        if not self.conn:
            print("âŒ KhÃ´ng cÃ³ káº¿t ná»‘i database")
            return False
        
        try:
            with self.conn.cursor() as cur:
                # DROP TABLE if exists
                print("ðŸ—‘ï¸  Äang xÃ³a báº£ng products...")
                cur.execute('DROP TABLE IF EXISTS public.products CASCADE;')
                self.conn.commit()
                print("âœ… Báº£ng products Ä‘Ã£ xÃ³a")
                
                # Recreate tá»« init.sql
                if os.path.exists('init.sql'):
                    print("ðŸ“ Recreate báº£ng tá»« init.sql...")
                    with open('init.sql', 'r', encoding='utf-8') as f:
                        cur.execute(f.read())
                    self.conn.commit()
                    print('âœ… Báº£ng products Ä‘Ã£ Ä‘Æ°á»£c táº¡o láº¡i tá»« init.sql')
                    return True
                else:
                    print('âŒ KhÃ´ng tÃ¬m tháº¥y init.sql')
                    return False
        except Exception as e:
            print(f"âŒ Error: {e}")
            return False
    
    def init_schema(self):
        """Khá»Ÿi táº¡o schema (náº¿u chÆ°a táº¡o)"""
        if not self.conn:
            print("âŒ KhÃ´ng cÃ³ káº¿t ná»‘i database")
            return False
        
        try:
            with self.conn.cursor() as cur:
                # Check if products table exists
                cur.execute("SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'products')")
                if cur.fetchone()[0]:
                    print("â„¹ï¸  Table 'public.products' Ä‘Ã£ tá»“n táº¡i")

                    # Verify required columns exist; if some are missing, try to ALTER TABLE to add them
                    required_columns = {
                        'id': 'UUID PRIMARY KEY DEFAULT gen_random_uuid()',
                        'website_id': 'INTEGER DEFAULT 0',
                        'website_name': "VARCHAR(255)",
                        'url': "VARCHAR(1000)",
                        'title': "VARCHAR(500)",
                        'price': 'FLOAT DEFAULT 0',
                        'original_price': 'FLOAT DEFAULT 0',
                        'currency': "VARCHAR(10) DEFAULT 'VND'",
                        'sku': "VARCHAR(255)",
                        'brand': "VARCHAR(255)",
                        'category': "VARCHAR(255)",
                        'description': 'TEXT',
                        'availability': "VARCHAR(100)",
                        'images': 'TEXT[]',
                        'user_id': 'UUID',
                        'created_at': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP',
                        'updated_at': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'
                    }

                    # Get existing columns
                    cur.execute("SELECT column_name FROM information_schema.columns WHERE table_schema='public' AND table_name='products'")
                    existing = {r[0] for r in cur.fetchall()}

                    missing = [col for col in required_columns.keys() if col not in existing]
                    if missing:
                        print(f"âš ï¸  Trang bá»‹ thiáº¿u cá»™t trong products: {missing}. Sáº½ cá»‘ gáº¯ng sá»­a báº±ng ALTER TABLE...")
                        for col in missing:
                            try:
                                # Note: don't re-add primary key if exists; if id missing, recreate table below
                                if col == 'id':
                                    raise Exception('id column missing - recreate required')
                                alter_sql = f"ALTER TABLE public.products ADD COLUMN {col} {required_columns[col]};"
                                cur.execute(alter_sql)
                                print(f"   âœ“ ÄÃ£ thÃªm cá»™t {col}")
                            except Exception as e:
                                print(f"   âŒ KhÃ´ng thÃªm Ä‘Æ°á»£c cá»™t {col}: {e}")

                        # If id missing (primary key) or critical mismatch, try recreating from init.sql
                        if 'id' not in existing:
                            print("âš ï¸  Cá»™t 'id' bá»‹ thiáº¿u. Thá»±c hiá»‡n DROP TABLE vÃ  táº¡o láº¡i tá»« init.sql (náº¿u cÃ³)...")
                            if os.path.exists('init.sql'):
                                cur.execute('DROP TABLE IF EXISTS public.products CASCADE;')
                                with open('init.sql', 'r', encoding='utf-8') as f:
                                    cur.execute(f.read())
                                self.conn.commit()
                                print('âœ… ÄÃ£ recreate báº£ng products tá»« init.sql')
                                return True
                            else:
                                print('âŒ KhÃ´ng tÃ¬m tháº¥y init.sql Ä‘á»ƒ recreate báº£ng')
                                return False

                    # Commit any ALTERs
                    self.conn.commit()

                    # Ensure there is a unique constraint/index on url to support ON CONFLICT (url)
                    try:
                        cur.execute("SELECT conname FROM pg_constraint WHERE conrelid = 'public.products'::regclass AND contype = 'u'")
                        unique_constraints = [r[0] for r in cur.fetchall()]
                        # Also check indexes
                        cur.execute("SELECT indexname FROM pg_indexes WHERE schemaname='public' AND tablename='products'")
                        indexes = [r[0] for r in cur.fetchall()]

                        has_unique_url = False
                        # Check if any unique constraint/index mentions 'url'
                        for uc in unique_constraints:
                            if 'url' in uc:
                                has_unique_url = True
                        for idx in indexes:
                            if 'url' in idx:
                                # Need to check index definition
                                cur.execute("SELECT indexdef FROM pg_indexes WHERE indexname = %s", (idx,))
                                idxdef = cur.fetchone()[0]
                                if 'unique' in idxdef.lower() and 'url' in idxdef.lower():
                                    has_unique_url = True

                        if not has_unique_url:
                            print("â„¹ï¸  Táº¡o UNIQUE INDEX trÃªn products(url) Ä‘á»ƒ há»— trá»£ ON CONFLICT...")
                            cur.execute('CREATE UNIQUE INDEX IF NOT EXISTS idx_products_url_unique ON public.products ((url));')
                            self.conn.commit()
                    except Exception as e:
                        print(f"âš ï¸ KhÃ´ng thá»ƒ Ä‘áº£m báº£o unique index trÃªn url: {e}")
                    return True
                
                # Try to create table from init.sql
                if os.path.exists('init.sql'):
                    print("ðŸ“ Táº¡o báº£ng products...")
                    with open('init.sql', 'r', encoding='utf-8') as f:
                        sql_content = f.read()
                        cur.execute(sql_content)
                        self.conn.commit()
                        print("âœ… Báº£ng products khá»Ÿi táº¡o thÃ nh cÃ´ng")
                        return True
                else:
                    print("â„¹ï¸  init.sql khÃ´ng tÃ¬m tháº¥y - giáº£ Ä‘á»‹nh báº£ng Ä‘Ã£ tá»“n táº¡i trÃªn remote DB")
                    return True
        
        except Exception as e:
            print(f"âŒ Schema init error: {e}")
            self.conn.rollback()
            return False
    
    def add_website(self, name, base_url, ai_provider='openai'):
        """ThÃªm website má»›i hoáº·c láº¥y ID cá»§a website Ä‘Ã£ tá»“n táº¡i"""
        if not self.conn:
            print("âŒ KhÃ´ng cÃ³ káº¿t ná»‘i database")
            return None
        
        try:
            from urllib.parse import urlparse
            
            domain = urlparse(base_url).netloc
            
            # Normalize domain: remove www prefix
            if domain.startswith('www.'):
                domain_normalized = domain[4:]
            else:
                domain_normalized = domain
            
            # Use website_name as unique key (better for file uploads)
            # Check if this website_name already exists in database
            with self.conn.cursor() as cur:
                cur.execute(
                    "SELECT DISTINCT website_id FROM products WHERE website_name = %s LIMIT 1",
                    (name,)
                )
                result = cur.fetchone()
                
                if result:
                    # Website exists, use existing ID
                    website_id = result[0]
                    print(f"âœ… Website exists: {name} (ID: {website_id})")
                else:
                    # New website, assign new ID
                    # Try domain mapping first (for known websites)
                    if domain_normalized in self.WEBSITE_MAPPING:
                        website_id = self.WEBSITE_MAPPING[domain_normalized]
                    else:
                        # Query max website_id from database
                        cur.execute("SELECT COALESCE(MAX(website_id), 0) FROM products")
                        max_id = cur.fetchone()[0]
                        website_id = max_id + 1
                    
                    print(f"âœ… New website: {name}")
            
            print(f"   Domain: {domain_normalized}")
            print(f"   Website ID: {website_id}")
            print(f"   Táº¥t cáº£ products sáº½ lÆ°u vÃ o: public.products")
            return website_id
        except Exception as e:
            print(f"âŒ Error adding website: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def import_products_from_json(self, json_file, website_id=None, website_name=None, user_id=None):
        """Import sáº£n pháº©m tá»« JSON file vÃ o báº£ng riÃªng cá»§a website"""
        if not self.conn:
            print("âŒ KhÃ´ng cÃ³ káº¿t ná»‘i database")
            return False
        
        if not os.path.exists(json_file):
            print(f"âŒ File khÃ´ng tÃ¬m tháº¥y: {json_file}")
            return False
        
        # VALIDATE USER_ID - Báº®T BUá»˜C PHáº¢I CÃ“ VÃ€ Tá»’N Táº I TRONG DATABASE
        if not user_id:
            print("âŒ Thiáº¿u user_id! Pháº£i Ä‘Äƒng nháº­p má»›i Ä‘Æ°á»£c crawl.")
            return False
        
        # Verify user exists in database
        try:
            user_uuid = uuid_lib.UUID(user_id) if isinstance(user_id, str) else user_id
        except (ValueError, AttributeError):
            print(f"âŒ user_id khÃ´ng há»£p lá»‡: {user_id}")
            return False
        
        # Check if user exists
        try:
            from sqlalchemy import create_engine
            from sqlalchemy.orm import Session
            
            # Táº¡o connection string
            conn_str = f"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.dbname}"
            engine = create_engine(conn_str)
            
            # Import models
            sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            from models.user import UserTable
            from models.ai_personality import AIPersonalityTable
            
            with Session(engine) as session:
                user = session.query(UserTable).filter(UserTable.id == user_uuid).first()
                
                if not user:
                    print(f"âŒ User {user_id} khÃ´ng tá»“n táº¡i trong database!")
                    print("   Vui lÃ²ng Ä‘Äƒng nháº­p trÆ°á»›c khi crawl.")
                    return False
                
                print(f"âœ… User verified: {user.full_name} ({user.email})")
        except Exception as e:
            print(f"âŒ Lá»—i xÃ¡c thá»±c user: {e}")
            return False
        
        try:
            # Náº¿u chÆ°a cÃ³ website_id, thÃªm website má»›i
            if not website_id:
                if not website_name:
                    # Extract tá»« tÃªn file
                    website_name = json_file.split('_')[0]
                
                # Láº¥y domain tá»« filename
                base_url = f"https://{website_name.replace('_', '.')}"
                website_id = self.add_website(website_name, base_url)
                if not website_id:
                    print(f"âŒ KhÃ´ng thá»ƒ táº¡o website")
                    return False
            
            # Láº¥y website info (simplified - just use website_name directly)
            if not website_name:
                website_name = "unknown"
            
            # Load JSON
            with open(json_file, 'r', encoding='utf-8') as f:
                products = json.load(f)
            
            print(f"ðŸ“¥ Äang import {len(products)} sáº£n pháº©m vÃ o products...")
            
            # Check existing products for this website
            with self.conn.cursor() as cur:
                cur.execute("SELECT COUNT(*) FROM products WHERE website_id = %s", (website_id,))
                existing_count = cur.fetchone()[0]
            
            print(f"   â„¹ï¸  Website hiá»‡n cÃ³ {existing_count} sáº£n pháº©m")
            
            # Prepare data for batch insert
            products_data = []
            skipped_invalid = 0
            duplicates_in_batch = 0
            
            seen_urls = set()
            
            for product in products:
                # Validate URL
                url = product.get('url', '').strip()
                if not url:
                    skipped_invalid += 1
                    continue
                
                # Validate Title (báº¯t buá»™c)
                title = product.get('title', '').strip()
                if not title:
                    skipped_invalid += 1
                    continue
                
                # Check duplicate in current batch
                if url in seen_urls:
                    duplicates_in_batch += 1
                    continue
                seen_urls.add(url)
                
                # Convert images list to PostgreSQL array format
                images = product.get('images', [])
                if not isinstance(images, list):
                    images = []
                # Convert to PostgreSQL array format if not empty
                if images:
                    images = images  # psycopg2 handles list to array conversion automatically
                else:
                    images = None
                
                # Clean price - náº¿u price > 1e15 hoáº·c khÃ´ng há»£p lá»‡, set to 0
                price = product.get('price') or 0
                try:
                    price = float(price)
                    if price > 1e15 or price < 0:
                        price = 0
                except:
                    price = 0
                
                original_price = product.get('original_price') or 0
                try:
                    original_price = float(original_price)
                    if original_price > 1e15 or original_price < 0:
                        original_price = 0
                except:
                    original_price = 0
                
                products_data.append((
                    str(uuid_lib.uuid4()),  # Generate new UUID for id as string
                    website_id,
                    website_name,
                    url,
                    title,  # ÄÃ£ validate á»Ÿ trÃªn, cháº¯c cháº¯n cÃ³ giÃ¡ trá»‹
                    price,
                    original_price,
                    product.get('currency', 'VND'),
                    product.get('sku', ''),
                    product.get('brand', ''),
                    product.get('category', ''),
                    product.get('description', ''),
                    product.get('availability', ''),
                    images,
                    str(user_uuid)  # user_uuid Ä‘Ã£ Ä‘Æ°á»£c validate á»Ÿ trÃªn
                ))
            
            # Batch insert vÃ o báº£ng products chung
            if products_data:
                with self.conn.cursor() as cur:
                    execute_values(cur, """
                        INSERT INTO products
                        (id, website_id, website_name, url, title, price, original_price, currency, sku, brand, category, description, availability, images, user_id)
                        VALUES %s
                        ON CONFLICT (url) DO UPDATE SET
                            title = EXCLUDED.title,
                            price = EXCLUDED.price,
                            original_price = EXCLUDED.original_price,
                            currency = EXCLUDED.currency,
                            sku = EXCLUDED.sku,
                            brand = EXCLUDED.brand,
                            category = EXCLUDED.category,
                            description = EXCLUDED.description,
                            availability = EXCLUDED.availability,
                            images = EXCLUDED.images,
                            user_id = EXCLUDED.user_id,
                            updated_at = CURRENT_TIMESTAMP;
                    """, products_data, page_size=self.BATCH_PAGE_SIZE)
                    
                    self.conn.commit()
            
            # Check final count
            with self.conn.cursor() as cur:
                cur.execute("SELECT COUNT(*) FROM products WHERE website_id = %s", (website_id,))
                final_count = cur.fetchone()[0]
            
            new_products = final_count - existing_count
            print(f"  âœ… ThÃªm {new_products} sáº£n pháº©m má»›i (tá»•ng: {final_count})")
            if skipped_invalid > 0:
                print(f"  âš ï¸  Bá» qua {skipped_invalid} sáº£n pháº©m khÃ´ng há»£p lá»‡ (khÃ´ng cÃ³ URL)")
            if duplicates_in_batch > 0:
                print(f"  âš ï¸  Bá» qua {duplicates_in_batch} duplicate URLs trong batch")
            
            return True
        
        except Exception as e:
            print(f"âŒ Import error: {e}")
            self.conn.rollback()
            return False
    
    def log_crawl(self, website_id, total_urls, products_found, products_with_price, products_with_images, status="success", error_msg=None, duration_seconds=0):
        """Ghi log crawl vÃ o database (disabled - simplified schema)"""
        # Simplified schema doesn't have crawl_logs table, so just skip logging
        print(f"\n  ðŸ“‹ LOG: {products_found} products ({products_with_price} with price, {products_with_images} with images) in {duration_seconds}s")
        return True
    
    def get_stats(self, website_id=None):
        """Láº¥y thá»‘ng kÃª cho website (simplified - queries public.products only)"""
        if not self.conn:
            return {}
        
        try:
            with self.conn.cursor() as cur:
                if website_id:
                    # Láº¥y stats tá»« báº£ng products chung cho specific website
                    cur.execute("""
                        SELECT
                            COUNT(*) as total_products,
                            COUNT(CASE WHEN price > 0 THEN 1 END) as products_with_price,
                            COUNT(CASE WHEN images IS NOT NULL AND array_length(images, 1) > 0 THEN 1 END) as products_with_images,
                            COUNT(CASE WHEN sku IS NOT NULL AND sku != '' THEN 1 END) as products_with_sku,
                            AVG(price) as avg_price,
                            MIN(price) as min_price,
                            MAX(price) as max_price,
                            MAX(website_name) as website_name
                        FROM products
                        WHERE website_id = %s
                    """, (website_id,))
                    
                    stats = cur.fetchone()
                    if stats and stats[0] > 0:
                        return {
                            'id': website_id,
                            'name': stats[7] or 'Unknown',
                            'total_products': stats[0],
                            'products_with_price': stats[1],
                            'products_with_images': stats[2],
                            'products_with_sku': stats[3],
                            'avg_price': stats[4],
                            'min_price': stats[5],
                            'max_price': stats[6]
                        }
                else:
                    # Láº¥y táº¥t cáº£ stats tá»« products table
                    cur.execute("""
                        SELECT
                            website_id,
                            website_name,
                            COUNT(*) as total_products,
                            COUNT(CASE WHEN price > 0 THEN 1 END) as products_with_price,
                            COUNT(CASE WHEN images IS NOT NULL AND array_length(images, 1) > 0 THEN 1 END) as products_with_images,
                            COUNT(CASE WHEN sku IS NOT NULL AND sku != '' THEN 1 END) as products_with_sku,
                            AVG(price) as avg_price,
                            MIN(price) as min_price,
                            MAX(price) as max_price
                        FROM products
                        GROUP BY website_id, website_name
                        ORDER BY total_products DESC
                    """)
                    
                    results = []
                    for row in cur.fetchall():
                        if row[2] > 0:  # Chá»‰ thÃªm náº¿u cÃ³ products
                            results.append({
                                'id': row[0],
                                'name': row[1] or 'Unknown',
                                'total_products': row[2],
                                'products_with_price': row[3],
                                'products_with_images': row[4],
                                'products_with_sku': row[5],
                                'avg_price': row[6],
                                'min_price': row[7],
                                'max_price': row[8]
                            })
                    return results
        except Exception as e:
            print(f"âŒ Error getting stats: {e}")
            return {} if website_id else []
    
    def query_products(self, website_id=None, brand=None, min_price=None, max_price=None, limit=50, offset=0):
        """Truy váº¥n sáº£n pháº©m tá»« báº£ng products chung"""
        if not self.conn:
            return []
        
        try:
            with self.conn.cursor() as cur:
                # Build query
                where_conditions = ["1=1"]
                params = []
                
                if website_id:
                    where_conditions.append("website_id = %s")
                    params.append(website_id)
                
                if brand:
                    where_conditions.append("brand = %s")
                    params.append(brand)
                
                if min_price:
                    where_conditions.append("price >= %s")
                    params.append(min_price)
                
                if max_price:
                    where_conditions.append("price <= %s")
                    params.append(max_price)
                
                where_clause = " AND ".join(where_conditions)
                
                query = f"""
                    SELECT id, website_name, url, title, price, sku, brand, images
                    FROM products
                    WHERE {where_clause}
                    ORDER BY price DESC
                    LIMIT %s OFFSET %s
                """
                
                params.extend([limit, offset])
                
                cur.execute(query, params)
                results = cur.fetchall()
                
                return [{
                    'id': r[0],
                    'url': r[1],
                    'title': r[2],
                    'price': r[3],
                    'sku': r[4],
                    'brand': r[5],
                    'images': r[6]
                } for r in results]
        
        except Exception as e:
            print(f"âŒ Query error: {e}")
            return []
    
    def get_crawl_history(self, website_id=None, limit=10):
        """Láº¥y lá»‹ch sá»­ crawl (disabled - simplified schema doesn't have crawl_logs)"""
        return []
    
    def get_crawl_stats_summary(self):
        """Láº¥y tÃ³m táº¯t thá»‘ng kÃª crawl (disabled - simplified schema doesn't have crawl_logs)"""
        return {
            'total_crawls': 0,
            'total_products': 0,
            'avg_duration': 0,
            'total_duration': 0,
            'success_rate': 0
        }
    
    def update_user_website_name(self, user_id, website_name):
        """Update website_name cá»§a user sá»­ dá»¥ng SQLAlchemy ORM"""
        try:
            # Import SQLAlchemy + models
            from sqlalchemy import create_engine
            from sqlalchemy.orm import Session
            import uuid as uuid_lib
            
            # Táº¡o connection string tá»« db config
            db_url = f"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.dbname}"
            engine = create_engine(db_url, echo=False)
            
            # Import UserTable model
            sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            from models.user import UserTable
            from models.ai_personality import AIPersonalityTable  # Import Ä‘á»ƒ fix relationship error
            
            # Parse user_id thÃ nh UUID
            try:
                user_uuid = uuid_lib.UUID(user_id)
            except (ValueError, AttributeError):
                print(f"  âŒ Invalid user_id format: {user_id}")
                return False
            
            # Update user
            with Session(engine) as session:
                user = session.query(UserTable).filter(UserTable.id == user_uuid).first()
                
                if user:
                    user.website_name = website_name
                    session.commit()
                    print(f"  âœ… Updated user {user_id} with website_name: '{website_name}'")
                    return True
                else:
                    print(f"  âš ï¸  User {user_id} not found in database")
                    return False
        
        except Exception as e:
            print(f"  âŒ Error updating user: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def close(self):
        """ÄÃ³ng káº¿t ná»‘i"""
        if self.conn:
            self.conn.close()
            print("âœ… Database connection closed")


if __name__ == "__main__":
    # Test
    db = DatabaseManager()
    
    if db.connect():
        db.init_schema()
        
        # Test: List all websites
        stats = db.get_stats()
        if stats:
            print("\nðŸ“Š WEBSITES:")
            for stat in stats:
                print(f"  - {stat['name']}: {stat['total_products']} products")
        
        db.close()
